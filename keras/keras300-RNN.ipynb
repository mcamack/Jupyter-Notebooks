{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Recurrent-Neural-Networks\" data-toc-modified-id=\"Recurrent-Neural-Networks-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Recurrent Neural Networks</a></span><ul class=\"toc-item\"><li><span><a href=\"#RNN-Overview\" data-toc-modified-id=\"RNN-Overview-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>RNN Overview</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sequence-Data-Applications\" data-toc-modified-id=\"Sequence-Data-Applications-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Sequence Data Applications</a></span></li><li><span><a href=\"#Notation\" data-toc-modified-id=\"Notation-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Notation</a></span></li><li><span><a href=\"#RNN-Model\" data-toc-modified-id=\"RNN-Model-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>RNN Model</a></span></li><li><span><a href=\"#Backpropagation-through-Time\" data-toc-modified-id=\"Backpropagation-through-Time-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>Backpropagation through Time</a></span></li></ul></li><li><span><a href=\"#RNN-Architectures\" data-toc-modified-id=\"RNN-Architectures-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>RNN Architectures</a></span><ul class=\"toc-item\"><li><span><a href=\"#Vanilla-RNN\" data-toc-modified-id=\"Vanilla-RNN-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Vanilla RNN</a></span></li></ul></li><li><span><a href=\"#Language-Modeling\" data-toc-modified-id=\"Language-Modeling-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Language Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Gated-Recurrent-Unit-(GRU)\" data-toc-modified-id=\"Gated-Recurrent-Unit-(GRU)-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Gated Recurrent Unit (GRU)</a></span></li><li><span><a href=\"#Long-short-Term-Memory-(LSTM)\" data-toc-modified-id=\"Long-short-Term-Memory-(LSTM)-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Long-short Term Memory (LSTM)</a></span></li></ul></li><li><span><a href=\"#Bi-directional-RNN-(BRNN)\" data-toc-modified-id=\"Bi-directional-RNN-(BRNN)-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Bi-directional RNN (BRNN)</a></span></li><li><span><a href=\"#Deep-RNNs\" data-toc-modified-id=\"Deep-RNNs-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Deep RNNs</a></span></li><li><span><a href=\"#Word-Representation\" data-toc-modified-id=\"Word-Representation-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Word Representation</a></span></li><li><span><a href=\"#Word-Embeddings\" data-toc-modified-id=\"Word-Embeddings-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Word Embeddings</a></span></li><li><span><a href=\"#Embedding-Matrix\" data-toc-modified-id=\"Embedding-Matrix-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Embedding Matrix</a></span></li><li><span><a href=\"#Word2Vec\" data-toc-modified-id=\"Word2Vec-1.9\"><span class=\"toc-item-num\">1.9&nbsp;&nbsp;</span>Word2Vec</a></span></li><li><span><a href=\"#Negative-Sampling\" data-toc-modified-id=\"Negative-Sampling-1.10\"><span class=\"toc-item-num\">1.10&nbsp;&nbsp;</span>Negative Sampling</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook summarizes recurrent neural networks (RNN) as presented in the following resources:\n",
    "* [Stanford CS224n: NLP w/Deep Learning](http://web.stanford.edu/class/cs224n/index.html)\n",
    "* [RNN Course by Andrew NG - YouTube](https://www.youtube.com/playlist?list=PLBAGcD3siRDittPwQDGIIAWkjz-RucAc7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Data Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Speech Recognition\n",
    "* Music Generation\n",
    "* Sentiment Classification\n",
    "* DNA Sequence Analysis\n",
    "* Machine Language Translation\n",
    "* Video Activity Recognition\n",
    "* Name Entity Recognition\n",
    " * Scan news articles and save the names of everyone mentioned\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/RNN_Ng_001.png\" alt=\"RNN_png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vocabulary** contains all the possible words. Commercial applications use dictionaries of 25,000 - 50,000 words. However, larger sizes are becoming more common... and the largest internet companies have up to 1,000,000+ entries\n",
    "\n",
    "Use 1-hot notation to represent a single word. So a 10,000 vector would be all zeroes except for a 1 in one spot. Ex: $x^{<1>}$ may represent the word \"and\" and it might be a 10,000 long vector with a 1 near the beginning in the 2nd spot.\n",
    "\n",
    "$\\begin{pmatrix}\n",
    "0 & 'a'\\\\\n",
    "1 & 'and'\\\\\n",
    ". & .\\\\\n",
    ". & . \\\\\n",
    ". & . \\\\\n",
    "0 & 'zyzzogeton\\\\\n",
    "\\end{pmatrix}\n",
    "$\n",
    "\n",
    "*Note above - zyzzogeton probably wouldn't be in our vocabulary because it's unlikely to occur over a threshold number of times in our corpus of training text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard neural network will not work:\n",
    "* Inputs/outputs can be of different length (padding doesn't help)\n",
    "* Won't share features learned across different positions of text\n",
    "* Like a CNN, we want the network to learn and then share that feature.   * This allows a feature (or piece of text) to be learned in one position and then applied to another area of the image (or section of text)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent Neural Network (RNN):\n",
    "* Activation value from timestep 1 is passed on to timestep 2\n",
    "* Activations at timestep 0 can be initialized to zeroes\n",
    "\n",
    "Forward Propagation Basic Processing:\n",
    "* Scans thru the data from left to right\n",
    "* **Parameters are shared across each timestep **\n",
    "* This example only uses old data in the sequence\n",
    " * Bi-directional RNN (BRNN) fix this\n",
    "* Activation Functions chosen for the Y output at each step are usually tanh or ReLU (need to fix vanishing gradient)\n",
    " * sigmoid if you have binary classification\n",
    " * softmax if multi-classifcation\n",
    "* Don't have to have outputs at each step! It could just be at the final output step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/RNN_Ng_002.png\" alt=\"RNN_png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/RNN_Ng_003.png\" alt=\"RNN_png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of carrying around 2 parameter matrics, they can be compressed into one. It simplifies notation when we have more complex models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/RNN_Ng_004.png\" alt=\"RNN_png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation through Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Same $W_a$ and $b_a$ values are used at each step (as well as $W_y$ and $b_y$\n",
    "* **For Backpropagation, we need a loss function**\n",
    " * take the sum of the element-wise loss at each step\n",
    " * can compute numbers allowing you to take derivatives wrt the params and then update the params using Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/RNN_Ng_007.png\" alt=\"RNN_png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many-to-many\n",
    "* Number of inputs equals number of outputs\n",
    "* ex: Encoder -> Decoder portions of 1 RNN to translate 1 language to another (only Decorder has outputs)\n",
    "\n",
    "Many-to-one\n",
    "* ex: take in a whole sentence, output one result (sentiment)\n",
    "\n",
    "One-to-many\n",
    "* ex: music generation by inputing 1 number (or no nums...)\n",
    "* synthesized outputs get fed to each next step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/RNN_Ng_005.png\" alt=\"RNN_png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language model gives probabilities of a sentence happening.\n",
    "\n",
    "Training:\n",
    "* need large corpus of text\n",
    "* tokenize each word to 1-hot vectors\n",
    "* possibly use EOS for end of sentence\n",
    "* vocabulary is of a set size\n",
    " * replace rare words with UNK (unknown) so they don't take the place of more used words\n",
    "\n",
    "RNN Model:\n",
    "* output at each time step is a vector of 10,000 (vocabulary size) with the probabilities of each word in the list occuring next\n",
    "* for the next step, try to figure out second word. Give it the correct first word this time as the \"memory\" input from the previous step\n",
    "* each step looks at the preceding X words to predict the current word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/RNN_Ng_006.png\" alt=\"RNN_png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling:\n",
    "\n",
    "Randomly generate a sentence from the trained RNN language model. Sample the output of each timestep's softmax output randomly, then pass that randomly chosen word in as the input to the next timestep (x<2> = y^<1>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vanishing Gradients:\n",
    "\n",
    "Most outputs are mainly influenced by closer inputs, it is hard for the RNN to backprop errors all the way from the end of a sentence to the beginning. Vanishing gradients occurs when the derivative exponentially decays and earlier parameters in the neural network get very smaller, or no updates, hence no learning. GRUs are useful for fixing this problem.\n",
    "\n",
    "Exploding Gradients:\n",
    "\n",
    "Gradient clipping can fix exponentially increasing gradients by capping the value at a certain number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gated Recurrent Unit (GRU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Modification to RNN hidden layer\n",
    "\n",
    "* GRU has new variable: c = memory cell\n",
    "* The memory cell can remember something for as long as you want\n",
    "* **Update gate is always ~ 0 or 1**\n",
    "* The job of the gate is to determine when to update the value of c\n",
    " * ex: remember a word from the beginning of a sentence as either plural or not (1 or 0). Use that info later to decide on a later word which depends on the plurality of an earlier word\n",
    " \n",
    "* $c$~$<t>$ is the update candidate which can replace $c^{<t>}$\n",
    "\n",
    "* The value of $\\Gamma_\\mu$ determines the \"amount\" of $c^{<t-1>}$ that is \"kept\" from the previous step. Because $\\Gamma_\\mu$ can be extremely small, the value of $c^{<t-1>}$ does not decay much and very long term dependencies can be maintained (also fixes the vanishing gradient issue)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/RNN_Ng_008.png\" alt=\"RNN_png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full GRU:\n",
    "\n",
    "* Most commonly used versions of an RNN\n",
    "* In addition to the **update gate**, there is also a **relevance gate**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/RNN_Ng_009.png\" alt=\"RNN_png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long-short Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* More powerful (and general) version of the GRU\n",
    "* There are now 3 gates instead of 2:\n",
    " * Gamma update\n",
    " * Gamma forget\n",
    " * Gamma output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/RNN_Ng_010.png\" alt=\"RNN_png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the right gate settings, $c^{<0>}$ could be passed all the way from the beginning to the end of a long temporal sequence. It would be able to remember data across a very large sequence.\n",
    "\n",
    "Peephole connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-directional RNN (BRNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effective for many NLP problems, but need to have the entire sequence of text before you can start. If this was speech recognition, you would have to wait for the person to stop talking in order to get the whole sequence before processing begins. More complex algorithms are able to work in real-time for speech recognition.\n",
    "\n",
    "* Need information from the future\n",
    "* Acyclic Graph\n",
    "* Even though it goes forward and backward, it's still forward propagation only - it just goes \"forward\" starting at each end at the same time\n",
    "* Output at each time would have an activation function multiplied by the forward and \"backward\" activations at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/RNN_Ng_011.png\" alt=\"RNN_png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 layers is deep for RNN ... usually don't see 10-100s of layers\n",
    "* may have deep NN off of each output for final prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/RNN_Ng_012.png\" alt=\"RNN_png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/\" alt=\"RNN_png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/\" alt=\"RNN_png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Representation\n",
    "* 1-hot vectors treat each as its own thing, with no general relationship between similar words (like apple and orange)\n",
    "* inter-product vectors across 1-hot encoded vectors is 0 (not good)\n",
    "* We can create a feature vector across words, ex: 300 feature vector:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/RNN_Ng_013.png\" alt=\"RNN_png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings\n",
    "* t-SNE can be used to create a 2D view of the 300D vector\n",
    "* Words get **embedded** into a 300D space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/RNN_Ng_014.png\" alt=\"RNN_png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* replace 1-hot encoded vectors with word embeddings, this enables transfer learning\n",
    "* Transfer Learning and word embedding:\n",
    " * 1B – 100B word corpus of text can be used for training word embeddings\n",
    " * transfer embedding to new task with smaller training set (10k words)\n",
    " * continue finetuning the word embeddings with new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogies\n",
    "\n",
    "* Man -> Woman as King -> ?\n",
    "* e_man – e_woman ~= e_king – e_w\n",
    "* subtract the embedding vectors and compare the resulting vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/RNN_Ng_015.png\" alt=\"RNN_png\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Find a word (w) that maximizes the similarity (e_w, e_king – e_man + e_woman)\n",
    "  * use Cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrix\n",
    "\n",
    "* selects a column out of the embedding matrix\n",
    "* Keras has an “Embedding” Layer\n",
    "\n",
    "Learning Word Embeddings\n",
    "* hyperparameter is the previous number of words used to guess next word\n",
    "* to really learn word embeddings, it’s good to have a few diff contexts:\n",
    " * last 4 words\n",
    " * last 1 word\n",
    " * nearby 1 word (skip gram – pick some word near it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip-grams\n",
    "\n",
    "Pick a target word from the sentence and then choose random context words from 1, 2, 3, etc. before and after. Now the algorithm starts to learn the target word as it relates to different context words\n",
    "* sample the context word randomly, but add certain selection criteria so simple and frequent words like \"a\" aren't constantly chosen\n",
    "* creates a pretty good embedding vector\n",
    "* takes a long time because have to process across all words in vocab (even at 10k words)\n",
    " * **Hierarchical Softmax** can help with classification speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* similar to skip-gram, but more efficient\n",
    "* select a context and another word, set the target to 1\n",
    "* select another k random words, set the target to 0 for each\n",
    " * k = 5-20 for smaller datasets, and 2-5 for larger datasets\n",
    " * chances of it being related is close to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
