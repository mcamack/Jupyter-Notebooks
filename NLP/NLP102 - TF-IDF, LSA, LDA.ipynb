{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF and LSA\n",
    "\n",
    "Term Frequency - Inverse Document Frequency (TF-IDF) helps to estimate the importance of each word in a chunk of text based on how common it is throughout a set of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "    'This is the first sentence',\n",
    "    'This is the second sentence',\n",
    "    'Something that has nothing to do with the others',\n",
    "    'This is the final sentence'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=True)\n",
    "vectors = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 15)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence 1</th>\n",
       "      <th>sentence 2</th>\n",
       "      <th>sentence 3</th>\n",
       "      <th>sentence 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>do</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347685</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>0.633146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347685</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0.404129</td>\n",
       "      <td>0.404129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.404129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nothing</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347685</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>others</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347685</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence</th>\n",
       "      <td>0.404129</td>\n",
       "      <td>0.404129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.404129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>something</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347685</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347685</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.330402</td>\n",
       "      <td>0.330402</td>\n",
       "      <td>0.181437</td>\n",
       "      <td>0.330402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>0.404129</td>\n",
       "      <td>0.404129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.404129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347685</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347685</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sentence 1  sentence 2  sentence 3  sentence 4\n",
       "do           0.000000    0.000000    0.347685    0.000000\n",
       "final        0.000000    0.000000    0.000000    0.633146\n",
       "first        0.633146    0.000000    0.000000    0.000000\n",
       "has          0.000000    0.000000    0.347685    0.000000\n",
       "is           0.404129    0.404129    0.000000    0.404129\n",
       "nothing      0.000000    0.000000    0.347685    0.000000\n",
       "others       0.000000    0.000000    0.347685    0.000000\n",
       "second       0.000000    0.633146    0.000000    0.000000\n",
       "sentence     0.404129    0.404129    0.000000    0.404129\n",
       "something    0.000000    0.000000    0.347685    0.000000\n",
       "that         0.000000    0.000000    0.347685    0.000000\n",
       "the          0.330402    0.330402    0.181437    0.330402\n",
       "this         0.404129    0.404129    0.000000    0.404129\n",
       "to           0.000000    0.000000    0.347685    0.000000\n",
       "with         0.000000    0.000000    0.347685    0.000000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(index=vectorizer.get_feature_names())\n",
    "\n",
    "for i,doc in enumerate(vectors):\n",
    "    df[f\"sentence {i+1}\"] = doc.T.todense()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA\n",
    "\n",
    "TF-IDF Limitations: two documents on the same subject, but with different word spellings, will end up not being related at all\n",
    "\n",
    "Latent Semantic Analysis (LSA) is used to create a vector representation of tf-idf word scores which turn into \"topic vectors\". This enables *semantic search* which can query documents based on their meaning or find similar documents. Vectors can be added and subtracted to learn new things, and vectors of similar length and direction end up having similar meanings!\n",
    "\n",
    "LSA is unsupervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA and LDiA\n",
    "\n",
    "Linear Discriminant Analysis (LDA) creates a single topic vector per document. Just compute the centroid of all TF-IDF vectors for each class in a multiclass classification problem (spam vs. non-spam) and find the line between each centroid. Further a TF-IDF vector is on the line tells you which class you're in.\n",
    "\n",
    "LDA is a supervised algorithm that needs labels for training.\n",
    "\n",
    "Latent Dirichlet Allocation (LDiA) can create multiple topic vectors per document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "                           solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "X = vectors.toarray()\n",
    "y = [10,10,0,10]\n",
    "\n",
    "clf = LDA()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([df.iloc[:,2].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34768534, 0.        , 0.        , 0.34768534, 0.        ,\n",
       "       0.34768534, 0.34768534, 0.        , 0.        , 0.34768534,\n",
       "       0.34768534, 0.18143663, 0.        , 0.34768534, 0.34768534])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
