{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python library for data mining and data analysis  \n",
    "Built on NumPy, SciPy, and matplotlib  \n",
    "Documentation: http://scikit-learn.org/stable/documentation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Shaping Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learns comes with a few standard datasets (iris and digits)  \n",
    "each dataset is a dictionary-like object holding the data and metadata  \n",
    ".data member stores the data as (n_samples, n_features)\n",
    ".target member stores the response variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate digits dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".data member contains the features used to classify the digit sample images  \n",
    "each pixel is a feature  \n",
    "there are 1797 image samples, each has 64 features (8x8 pixels)  \n",
    "this is the same data that shows up in the .images member, but flattened into 1x64 shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
      " 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
      "  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
      "  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(digits.data.shape)\n",
    "print(digits.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".target member contains the truth label for each image  \n",
    "There are 1797 target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797,)\n",
      "[0 1 2 ... 8 9 8]\n"
     ]
    }
   ],
   "source": [
    "print(digits.target.shape)\n",
    "print(digits.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".target_names member has the name of each target variable (0-9 for each number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(digits.target_names.shape)\n",
    "print(digits.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".images member contains the actual image samples  \n",
    "there are 1797 images which are 8x8 pixels\n",
    "this is the same data from the .data member, but reshaped into an 8x8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 8, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(digits.images.shape)\n",
    "digits.images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the above array as an image  \n",
    "Create a second image which just shows grayscale  \n",
    "Notice the light pixels are 0 in the array, dark pixels are closer to 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting some data as images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use [pyplot](http://matplotlib.org/api/pyplot_api.html) to display the first and last images  \n",
    "convert to grayscale to reduce the color data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(digits.images[0])\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(digits.images[0], cmap=plt.cm.gray_r)\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(digits.images[1796])\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(digits.images[1796], cmap=plt.cm.gray_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning and Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "an estimator is fit with training data in order to predict unseen samples  \n",
    "scikit-learn uses a Python object which implements the fit(X,y) and predict(T) methods  \n",
    "<b>support vector classification</b> ([sklearn.svm.SVC](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)) is an example <b>classification estimator</b>  \n",
    "SVC has hyperparameters for gamma and C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "classifier = svm.SVC(gamma=0.001, C=100.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the SVC is trainined (fit) with all of the data except the last item  \n",
    "then use the SVC to predict what the last item should be classified as using this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(digits.data[:-1], digits.target[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(digits.data[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target[1796]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVC correctly classifies the last image based on what is listed in the .target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
